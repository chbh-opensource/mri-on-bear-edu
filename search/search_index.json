{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MRI on BEAR","text":"<p>MRI on BEAR is a collection of educational resources created by members of the Centre for Human Brain Health (CHBH) to provide basic introduction to fundamentals in magnetic resonance imaging (MRI) data analysis, data analysis tools and computational resources available to the University of Birmingham research community.</p>"},{"location":"#about-this-website","title":"About this website","text":"<p>This website contains workshop materials created for MSc module Magnetic Resonance Imaging in Cognitive Neuroscience (MRICN) and its earlier version (Fundamentals in Brain Imaging) at the School of Psychology, University of Birmingham. It is a ten-week course consisting of lectures and workshops introducing main techniques of functional and structural brain mapping using MRI with a strong emphasis on functional MRI (fMRI) but not limited to fMRI. Topics include the physics of MRI, and introduction to fMRI experimental design and to analysis of fMRI and other types of MRI data. This website includes only workshop materials aimed at very basic training in analysis of brain imaging data and data visualization. </p> <p>Accessing additional course materials</p> <p>If you are a CHBH member and would like access to MRICN lecture recordings etc. please contact one of the teaching staff members listed below.</p>"},{"location":"#learning-objectives","title":"Learning objectives","text":"<p>At the end of the course you will be able to:</p> <ul> <li>Demonstrate an understanding of the basic concepts involved in MRI</li> <li>Show an understanding of how to design fMRI experiments</li> <li>Have the ability to work with BlueBEAR in a Linux environment and to use appropriate software to view and interpret MRI data</li> <li>Be able to analyse simple fMRI experiments and conduct basic tractography analysis</li> </ul>"},{"location":"#contributors-and-teaching-staff","title":"Contributors and Teaching Staff","text":"Dr Magdalena Chechlacz <p>Role: Course Lead</p> <p>Magdalena Chechlacz is an Assistant Professor in Cognition and Ageing at the School of Psychology, University of Birmingham. She initially trained and carried out a doctorate in cellular and molecular biology (2002). After working as a biologist (Larry L. Hillblom Foundation Fellowship at the University of California, San Diego) she decided on a career change to a more human-oriented science and neuroimaging. In order to gain formal training in cognitive neuroscience and neuroimaging, she completed a second doctorate in psychology at the University of Birmingham under the supervision of Glyn Humphreys (2012). From 2013 to 2016, she held a British Academy Postdoctoral Fellowship and EPA Cephalosporin Junior Research Fellowship, Linacre College at the University of Oxford. In 2016, Dr Chechlacz returned to the School of Psychology, University of Birmingham as a Bridge Fellow.</p>  m.chechlacz@bham.ac.uk  Magda GitHub  Magda Twitter  0000-0003-1811-3946 <p></p> <p> </p> Aamir Sohail <p>Role: Teaching Assistant</p> <p>Aamir Sohail is an MRC Advanced Interdisciplinary Methods (AIM) DTP PhD student based at the Centre for Human Brain Health (CHBH), University of Birmingham, where he is supervised by Lei Zhang and Patricia Lockwood. He completed a BSc in Biomedical Science at Imperial College London, followed by an MSc in Brain Imaging at the University of Nottingham. He then worked as a Junior Research Fellow at the Centre for Integrative Neuroscience and Neurodynamics (CINN), University of Reading. Outside of research, he is also passionate about facilitating inclusivity and diversity in academia, as well as promoting open and reproducible science.</p>  axs2210@bham.ac.uk  sohaamir  AamirNSohail  0009-0000-6584-4579  sohaamir.github.io <p></p> <p>Many thanks to our contributors for creating and maintaining these resources!</p> <sub>ajquinn</sub>\ud83d\udea7 \ud83d\udd8b <sub>Aamir Sohail</sub>\ud83d\udea7 \ud83d\udd8b <p></p> <p>Additional contributors</p> <p>Thanks to ...</p>"},{"location":"resources/","title":"Resources","text":"<p>Here is a (non-exhaustive) list of links and pages for neuroscientists covering skills related to working with neuroimaging data, both with the concepts and practical application. </p> <p>Contributing to the list</p> <p>Feel free to suggest additional resources to the list by opening a thread on the GitHub page!</p>"},{"location":"resources/#existing-lists-of-resources","title":"Existing lists of resources","text":"<p>Here are some current 'meta-lists' which already cover a lot of resources themselves: </p> <ul> <li>Methods in Neuro Steven Weisberg's GitHub extensive list of resources covering the physics of MRI/fMRI, computational/programming, tools for the analysis of MRI/fMRI data, and online datasets, as part of his 'Methods in Neuroimaging' course at the University of Florida.</li> <li>Hitchhacker's guide to the brain A 'docs' style website with lists of resources for each stage of neuroimaging analysis including file organisation, planning. preregistration, data collection, pre-processing and analysis, and sharing data. By Remi Gau, McGill University and others.</li> <li>On-line neuroimaging resources A farily comprehensive list of 'softwares, databases, tutorials, blogs and other resources relevant to learn about neuroimaging or to help perform neuroimaging analysis'. Curated by Remi Gau, McGill University.</li> <li>Dartbrains A notebook style introduction to neuroimaging in Python. The materials cover how scanner generates data, how psychological states can be probed in the scanner, and how this data can be processed and analyzed. Created by Luke Chang, Dartmouth College.</li> <li>Awesome Magnetic Resonance Imaging (MRI) 'A curated list of delightful Magnetic Resonance (MR) courses, books, lectures, papers, blogs and free resources.' Created by Daniel Gomez, Harvard/MIT.</li> <li>Awesome Neuroscience 'A curated list of awesome neuroscience libraries, software and any content related to the domain.'  Created by Akash Tandon.</li> <li>fMRI-Resources A GitHub list not dissimilar to this one, providing information and resources on functional MRI. Created by John Pyles.</li> </ul>"},{"location":"resources/#neuroimaging","title":"Neuroimaging","text":"Conceptual understanding <p>Struggling to grasp the fundamentals of MRI/fMRI? Want to quickly refresh your mind on the physiological basis of the BOLD signal? Well, these resources are for you!</p> <ul> <li>Principles of fMRI The OG YouTube series for understanding the conceptual basis of MRI/fMRI. Created by Martin Lindquist and Tor Wager of Dartmouth College.</li> <li>Neuroimaging Research Methods Another YouTube channel for learning about MRI/fMRI including research methods. Created by Rasmus Birn, University of Wisconsin-Madison.</li> <li>Introduction to Principles of MRI A short book and associated simulation code for learning the principles of magnetic resonance imaging (MRI). Created by Peder Larson for students at UCSF.</li> <li>Questions and Answers in MRI Ever had a question about the basis of MRI/fMRI? Written from the perspective of a physicist, this website was specifically made to answer these questions. Created by Allen Elster, Washington University School of Medicine.</li> <li>fMRI Bootcamp A lecture series on fMRI, both conceptual and methodological by Rebecca Saxe, MIT.</li> <li>MIT 9.13 The Human Brain, Spring 2019 A course which 'surveys the core perceptual and cognitive abilities of the human mind and explores how they are implemented in the brain'. Delivered by Nancy Kanwisher, MIT.</li> </ul> Analysis of fMRI data <ul> <li>Introduction to Working with MRI Data in Python A Software Carpentries course covering MRI file types, organisational formats (e.g., BIDS) and working with open datasets.</li> <li>Andy's Brain Book The OG of neuroimaging tutorials. I don't know many trainee neuroimagers who haven't used Andy's amazing guides. Highly recommended to also check out his YouTube channel as well. Created by Andrew Jahn, University of Michigan.</li> <li>NI-edu A website covering two courses, \u201cfMRI-introduction\u201d (basic concepts and methodology of functional MRI (fMRI) research) and \u201cfMRI-pattern-analysis\u201d (machine-learning based \u2018decoding\u2019 and representational similarity analysis (RSA)), which are in a notebook format. Created by Lucas Snoek, University of Amsterdam.</li> <li>U of A: Neuroimaging Core Documentation Docs covering a range of neuroimaging tutorials including BIDS, ANTS, FSL, ITK-SNAP and more. Created by Dianne Paterson, University of Arizona.</li> <li>Data analysis for Neuroimaging (DAFNI) Denis Schluppeck's materials for the MSc Cognitive Neuroscience course at the University of Nottingham, covering SPM, git, FSL and MATLAB.</li> <li>Practice and theory of brain imaging A comprehensive course on neuroimaging in Python, with modules on reproducibility in programming/neuroimaging. Created by the Nipraxis team (Matthew Brett, Chris Markiewicz, Oscar Estaban, Zvi Baratz, Peter Rush).</li> <li>Psych 214 \u2013 functional MRI methods A 'hands-on course teaching the principles of functional MRI (fMRI) data analysis' created for students at UC Berkeley by Matthew Brett and JB Poline.</li> </ul>"},{"location":"resources/#programming","title":"Programming","text":"Unix/Linux <ul> <li>The Unix Shell Software Carpentries workshop on Unix.</li> <li>Ubuntu Linux Guide Nutanix's guide to Linux on Ubuntu.</li> </ul>"},{"location":"resources/#textbooks","title":"Textbooks","text":"<ul> <li> <p>An Introduction to Resting State fMRI Functional Connectivity (2017, Oxford University Press) by Janine Bijsterbosch, Stephen M. Smith, and Christian F. Beckmann</p> </li> <li> <p>Handbook of Functional MRI Data Analysis (2011, Cambridge University Press) by Russell A. Poldrack, Jeanette A. Mumford, and Thomas E. Nichols</p> </li> <li> <p>Introduction to Functional Magnetic Resonance Imaging (1998, Cambridge University Press) by Richard B. Buxton</p> </li> <li> <p>Introduction to Neuroimaging Analysis (2018, Oxford University Press) by Mark Jenkinson and Michael Chappell</p> </li> <li> <p>Short Introduction to Brain Anatomy for Neuroimaging (2018, Oxford University Press) by Mark Jenkinson and Michael Chappell</p> </li> <li> <p>Short Introduction to the General Linear Model (2018, Oxford University Press) by Mark Jenkinson and Michael Chappell</p> </li> <li> <p>Short Introduction to MRI Physics (2018, Oxford University Press) by Mark Jenkinson and Michael Chappell</p> </li> </ul>"},{"location":"setting-up/","title":"Setting up access to BlueBEAR and the BEAR Portal","text":"<p>Before you start with any workshop materials you will need to familiarise yourself with CHBH\u2019s computational resources (BlueBEAR). The following pages are aimed at helping you get started. </p> <p>To put these workshop materials into practical use you will be expected to understand what BlueBEAR is, what it is used for and to make sure you have access.</p> <p>Student Responsibility</p> <p>If you are an MSc student taking the MRICN module, please note that while there will be help available during all in person workshops in case you have any problems with using the BEAR Portal, it is your responsibility to make sure that you have access, and you are familiar with information provided in pre-workshop materials. Failing to gain an understanding of BlueBEAR and using BEAR Portal will prevent you from participating in MRICN brain imaging practical sessions and completing module\u2019s main assessment (data analysis). </p>"},{"location":"setting-up/#what-are-bear-and-bluebear","title":"What are BEAR and BlueBEAR?","text":"<p>BEAR stands for Birmingham Environment for Academic Research and is a collection of services provided specifically for researchers at the University of Birmingham. BEAR services are used by the researchers at Centre for Human Brain Health (CHBH) for various types of neuroimaging data analysis.</p> <p>BEAR services and basic resources, such the ones we will be using for the purpose of the MRICN module, are freely available to the University of Birmingham research community. Extra resources which might be needed for some research projects can be purchased e.g., access to dedicated nodes and extra storage. This is something your PI/MSc/PhD project supervisor might be using and will give you access to.</p> <p> </p> <p>BlueBEAR refers to the Linux High Performance Computing (HPC) environment which (1) enables researchers to run jobs simultaneously on many servers (thus providing fast and efficient processing capacity for data analysis), and (2) gives easy access to multiple apps, software libraries (e.g., software we will be using in this module to analyse MRI data), as well as various software development tools. As computing resources on BlueBEAR rely on Linux, in Workshop 1 you will learn some basic commands, which you will need to be familiar with to participate in subsequent practical sessions and to complete the module\u2019s main assessment (data analysis assessment). More Linux commands and basic principle of scripting will be introduced in subsequent workshops.</p> <p>There are two steps to gaining access to BlueBEAR:</p> <ul> <li>Being a member on an active BEAR project </li> <li>Having a BEAR Linux account</li> </ul> <p>Gaining access to BEAR Projects</p> <p>Only a member of Academic staff e.g., your project supervisor or module lead can apply for a BEAR project. As a student you cannot apply for a BEAR project. If you are registered as a student on the MRICN module, you have been added as member to the project chechlmy-chbh-mricn. If not please contact your PI to provide you with access to a BEAR project.</p> <p>So, you are already a member of a BEAR project giving you BlueBEAR access, but you will still need to activate your BEAR Linux account via the self-service route or the service desk form. The information on how to do it and step-by-step instructions are available on the BEAR website, see the following link.</p> <p>Please follow these steps as above to make sure you have a BEAR Linux account before starting with workshop 1 materials. To do this you will need to be on campus or using the University Remote Access Service (VPN). </p>"},{"location":"setting-up/#checking-access-to-bear-portal","title":"Checking access to BEAR Portal","text":"<ul> <li>In a web browser navigate to https://portal.bear.bham.ac.uk to access the BEAR Portal</li> <li>To log in please use your university username and password </li> <li>First select the \u2018University of Birmingham\u2019 button as below and next log in via the University\u2019s Single Sign-On page </li> </ul> <p>Remember that the BEAR Portal is only available on campus or using the VPN!</p> <p> </p> <p>If your log in is successful, you will be directed to the main BEAR Portal page as below. This means that you have successfully launched the BEAR Portal.</p> <p> </p> <p>If you get to this page, you are ready for Workshop 1. For now, you can log out. If you have any problems logging on to BEAR Portal, please email chbh-help@contacts.bham.ac.uk for help and advice. </p>"},{"location":"setting-up/#bear-storage","title":"BEAR Storage","text":"<p>The storage associated with each BEAR project is called the BEAR Research Data Store (RDS). Each BEAR project gets 3TB of storage space for free, but researchers (e.g., your MSc project supervisor) can pay for additional storage if needed. The RDS should be used for all data, job scripts and output on BlueBEAR.</p> <p> </p> <p>If you are registered as a student on the MRICN module, all the data and resources you will need to participate in the MRICN workshops and to complete the module\u2019s main assessment (data analysis assessment) have been added to the MRICN module RDS, and you have been given access to the folder <code>/rds/projects/c/chechlmy-chbh-mricn</code>. When working on your MSc project using BEAR services, your supervisor will direct you to the relevant RDS project.</p> <p>External access to data</p> <p>If you are not registered on the module and would like access to the data, please contact one of the teaching staff members.</p>"},{"location":"setting-up/#finding-additional-information","title":"Finding additional information","text":"<p>There is extensive BEAR technical documentation provided by University of Birmingham BEAR services (see links below). While for the purpose of this module, you are not expected to be familiar with all the provided there information, you might find it useful if you want to know more about computing resources available to researchers at CHBH via BEAR services, especially if you will be using BlueBEAR (e.g., for your MSc project).</p> <p>You can find out more about BEAR, BlueBEAR and RDS on the dedicated BEAR webpages: </p> <ul> <li> <p>University of Birmingham BEAR Homepage</p> </li> <li> <p>More information on BlueBEAR</p> </li> <li> <p>More information on Research Data Storage</p> </li> </ul>"},{"location":"contributing/contributing/","title":"Contributing","text":"<p>MRI on BEAR is hosted on GitHub. If you have any questions, comments, or suggestions for the website, please open an issue or feel free to fork the repository and maket he changes yourself!</p> <p>Details on how to do so are found on the repository's <code>README</code>. More detailed inforamtion of making changes are located within the <code>contributing_guide.md</code> file within the repository's <code>root</code>.</p>"},{"location":"contributing/contributing/#license","title":"License","text":"<p>All content in this book (ie, any files and content in the <code>docs/</code> folder) is licensed under the Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license. Please see the <code>LICENSE</code> in the <code>GitHub</code> repository for more details.</p>"},{"location":"workshop1/intro-to-bluebear/","title":"Introduction to the BlueBEAR portal","text":"<p>At this point you should know how to log in and access the main BEAR Portal page. Please navigate to https://portal.bear.bham.ac.uk, log in and launch the BEAR Portal; you should get to the page as below.</p> <p> </p> <p>BlueBEAR Portal is a web-based interface enabling access to various BEAR services and BEAR apps including:</p> <ul> <li>Files in RDS storage</li> <li>Data science apps and software</li> <li>BlueBEAR GUI </li> <li>Code Server Editor</li> <li>Submitting jobs to run on BlueBEAR cluster</li> <li>Information on currently running jobs and interactive sessions.</li> </ul> <p> BlueBEAR portal is basically a user friendly alternative to using the command line interface, your computer terminal.</p> <p> </p> <p>To view all files and data you have access to on BlueBEAR, click on \u201cFiles\u201d as illustrated above. You will see your home directory (your BEAR Linux home directory), which you will be able to access to from Linux Desktop (see below) and all RDS projects you are member of. You should be able to see there <code>/rds/projects/c/chechlmy-chbh-mricn</code> (MRICN module\u2019s RDS project). By selecting the \u201cHome Directory\u201d or any \u201cRDS project\u201d you will open a second browser tab, displaying the content. In the example below, you see the content of one of my projects.</p> <p> </p> <p>Inside the module\u2019s RDS project, you will find that you have a folder labelled xxx, where xxx is your University of Birmingham ADF username. If you navigate to that folder <code>rds/projects/c/chechlmy-chbh-mricn/xxx</code>, you will be able to perform various file operations from there. However, for now, please do not move, download, or delete any files.</p> <p>Data confidentiality</p> <p>Please also note that the MRI data you will be given to work with, should be used on BlueBEAR only and not downloaded on your personal desktop or laptop computer!</p>"},{"location":"workshop1/intro-to-bluebear/#launching-the-bluebear-gui","title":"Launching the BlueBEAR GUI","text":"<p>The BlueBEAR Portal options in the menu bar, \u201cJobs\u201d, \u201cClusters\u201d and \u201cMy interactive sessions\u201d can be used to submit and edit jobs to run on the BlueBEAR cluster and to get information about your currently running jobs and interactive sessions. Some of these processes can be also executed using Code Server Editor (VS Code) accessible via Interactive Apps. We won\u2019t explore these options in detail now but some of these will be introduced later when needed. </p> <p> </p> <p>For example, from the \u201cCluster\u201d option you can jump directly on BlueBEAR terminal and by using this built-in terminal, submit data analysis jobs and/or employ own contained version of neuroimaging software rather than software already available on BlueBEAR. We will cover containers, scripting and submitting jobs in later workshops. For now, just click on this option and see what happens; you can subsequently exit/close the terminal page.</p> <p>Finally, from the BlueBEAR Portal menu bar you can select the \u201cInteractive Apps\u201d and from there access various GUI applications you wish to use, including JupyterLab, RStudio, MATLAB and most importantly BlueBEAR GUI, which we will be using to analyse MRI data in the subsequent workshops. </p> <p> </p> <p>Please select BlueBEAR GUI. This will bring up a page for you to specify options for your job to start BlueBEAR GUI. You can leave some of these options as default. But please change \u201cNumber of Hours\u201d to 2 (our workshops will last 2 hours; for some other analysis tasks you might need more time) and make sure that the selected \u201cBEAR Project\u201d is <code>chechlmy-chbh-mricn</code>. Next click on Launch.</p> <p> </p> <p>It will take few minutes for the job to start. Once it\u2019s ready you\u2019ll see an option to connect to the BlueBEAR GUI. Click on Launch BlueBEAR GUI. </p> <p> </p> <p>Once you have launched the BlueBEAR GUI, you are in a Linux environment, on a Linux Desktop. The next sections will introduce you to how navigate and use this environment.</p> <p>Re-launching the BlueBEAR GUI</p> <p>In the main window of the BlueBEAR portal you will be able to see that you have an Interactive session running (the information above will remain there). This is important as if you close the Linux Desktop by mistake, you can click on Launch BlueBEAR GUI again to open it.</p>"},{"location":"workshop1/intro-to-linux/","title":"Introduction to Linux","text":"<p>Linux is a computer Operating System (OS) like, but different from, Microsoft Windows or Mac OS. Linux is very widely used in the academic world especially in the sciences. It is derived from one of the oldest and most stable and used OS platforms around, Unix. We use Linux on BlueBEAR. Many versions of Linux are freely available to download and install, including CentOS (Community ENTerprise Operating System) and Debian, which you might be familiar with. You can also use these operating systems with Microsoft Windows in Dual Boot Environment on your laptop or desktop computer. </p> <p>Linux and neuroimaging</p> <p>Linux is particularly suited for clustering computers together and for efficient batch processing of data. All major neuroimaging software runs on Linux. This includes FSL, SPM, AFNI, and many others. Linux, or some version of Unix, is used in almost all leading neuroimaging centres. Both MATLAB and Python also run well in a Linux environment.</p> <p>If you work in neuroimaging, it is to your advantage to become familiar with Linux. The more familiar you are, the more productive you will become. For some of you, this might be a challenge. The environment will present a new learning experience, one that will take time and effort to learn. But in the end, you should hopefully realize that the benefits of learning to work in this new computer environment are indeed worth the effort. Linux is not like the Windows or Mac OSX environments. It is best used by typing commands into a Terminal client and by writing small batch command programs. Frequently you may not need to use the mouse. Some parts of Linux may seem old-fashioned or counter intuitive. Using the Linux environment alone may take some getting used to. We will now explore using the Linux terminal.</p>"},{"location":"workshop1/intro-to-linux/#using-the-linux-terminal","title":"Using the Linux Terminal","text":"<p>BlueBEAR GUI enables to load various apps and applications by using the Linux environment and a built-in Terminal client. Once you have launched the BlueBEAR GUI, you will see a new window and from there you can open the Terminal client. There are different ways to open Terminal in BlueBEAR GUI window as illustrated below.</p> <p>Either by selecting from the drop-down menu:</p> <p> </p> <p> Or by selecting the folder at the bottom of the screen:</p> <p> </p> <p> In either case you will load the terminal:</p> <p> </p> <p> Once you have started the terminal you, you will be able to load required applications (e.g., to start the FSL GUI). FSL (FMRIB Software Library) is a neuroimaging software package we will be using in our workshops for MRI data analysis. </p> <p>When using the BlueBEAR GUI Linux desktop, you can simultaneously work in four separate spaces/windows. For example, if you are planning on using multiple apps, rather than opening multiple terminals and apps in the same space, you can move to another space. You can do that by clicking on \u201cworkspace manager\u201d in Linux desktop window.</p> <p> </p> <p>Linux is fundamentally a command line-based operating system, so although you can use the GUI interface with many applications, it is essential you get used to issuing commands through the Terminal interface to improve your work efficiency. </p> <p>Make sure you have an open Terminal as per instructions above. Note that a Terminal is a text-based interface, so generally the mouse is not much use. You need to get used to taking your hand off the mouse and letting go of it. Move it away, out of reach. You can then get used to using both hands to type into a Terminal client. </p> <p><code>[chechlmy@bear-pg0210u07a ~]$</code> as shown above in the Terminal Client is known as the system prompt. The prompt usually identifies the user and the system hostname. You can type commands at the system prompt (press the Enter key after each command to make it run). The system then returns output based on your command to the same Terminal. Try typing <code>ls</code> in the Terminal.</p> <p>This command tells Linux to print a list of the current directory contents. We will get back later to basic Linux commands, which you should learn to use BlueBEAR for neuroimaging data analysis. You may wonder why you should invest the time to learn the names of the various commands needed to copy files, change directories and to do general things such as run image analysis programs via the command line. This may seem rather clunky. However, the commands you learn to run on the command line in a terminal can alternatively be written in a text file. This text file can then be converted to a batch script that can be run on data sets using the BlueBEAR cluster, potentially looping over hundreds or thousands of different analyses, taking many days to run. This is vastly more efficient and far less error prone than using equivalent graphical tools to do the same thing, one at a time.</p> <p>When you open a new terminal window it opens in a particular directory. By default, this will be your home directory: </p> <p><code>/rds/homes/x/xxx</code> </p> <p>or the Desktop folder in your home directory:</p> <p><code>/rds/homes/x/xxx/Desktop</code>(where x is the first letter of your last name and xxx is your University of Birmingham ADF username).</p> <p>On BlueBEAR files are stored in directories (folders) and arranged into a tree hierarchy. </p> <p>Examples of directories on BlueBEAR:</p> <ul> <li><code>/rds/homes/x/xxx</code> (your home directory) </li> <li><code>/rds/projects/c/chechlmy-chbh-mricn</code> (our module RDS project directory) </li> </ul> <p>Directory separators on Linux and Windows</p> <p>/ (forward slash) is the Linux directory separator. Note that this is different from Windows (where the backward slash \\ is the directory separator).</p> <p>The current directory is always called <code>.</code> (i.e. a single dot)  The directory above the current directory is always called <code>..</code> (i.e. dot dot)  Your home directory can always be accessed using the shortcut <code>~</code> (the tilde symbol). Note that this is the same as <code>/rds/homes/x/xxx</code>.</p> <p>You need to remember this to use and understand basic Linux Commands.</p>"},{"location":"workshop1/intro-to-linux/#basic-linux-commands","title":"Basic Linux Commands","text":"<p>pwd (Print Working Directory) </p> <p>In a Terminal type <code>pwd</code> followed by the return (enter) key to find out the name of the directory where you are.  You are always in a directory and can (usually) move to directories above you or below to subdirectories. </p> <p>For example if you type <code>pwd</code> in your terminal you will see: <code>/rds/homes/x/xxx</code>    (e.g., <code>/rds/homes/c/chechlmy</code>)</p> <p>cd (Change Directory) </p> <p>In a Terminal window, type <code>cd</code> followed by the name of a directory to gain access to it. Keep in mind that you are always in a directory and normally are allowed access to any directories hierarchically above or below.</p> <p>Type in your terminal the examples below:</p> <p><code>cd /rds/projects</code></p> <p><code>cd /rds/homes/</code></p> <p><code>cd ..</code> (to change to the directory above using .. shortcut) </p> <p>To find out where you are now, type <code>pwd</code>:</p> <p>(answer: <code>/rds</code>)</p> <p>If the directory is not located above or below the current directory, then it is often less confusing to write out the complete path instead.  Try this in your terminal:</p> <p><code>cd /rds/homes/x/xxx/Desktop</code> (where x is the first letter of your last name and xxx is your ADF username)</p> <p>Changing directories with full paths</p> <p>Note that it does not matter what directory you are in when you execute this command, the directory will always be changed based on the full pathway you specified. </p> <p>Remember that the tilde symbol <code>~</code> is a shortcut for your home directory. Try this: </p> <pre><code>cd /rds/projects \ncd ~ \npwd\n</code></pre> <p>You should be now back in your home directory.</p> <p>ls (List Files) </p> <p>The ls command (lowercase L, S) allows you to see a summary list of the files and directories located in the current directory. Try this: </p> <pre><code>cd /rds/projects/c\nls\n</code></pre> <p>(you should now see a long list of various BEAR RDS projects)</p> <p>Before moving to the next section, please close your terminal by clicking on \u201cx\u201d in the top right of the Terminal.</p> <p>cp (Copy files/directories) </p> <p>The <code>cp</code> command will copy files and/or directories FROM a source TO a destination in the current working directory. This command will create the destination file if it doesn't exist. In some cases, to do that you might need to specify a complete path to a file location.</p> <p>Here are some examples (please do not type them, they are only examples):</p> Command Function <code>cp myfile yourfile</code> Basic file copy (in current directory) <code>cp data data_copy</code> Copy a directory (but not subdirs) <code>cp -r ~fred/data .</code> Recursively copy fred' dir to current dir <code>cp ~fred/fredsfile myfile</code> Copy remote file and rename it <code>cp ~fred/* .</code> Copy all files from fred's dir to current dir <code>cp ~fred/test* .</code> Copy all files that begin with test e.g. test, test1.txt <p>In the subsequent workshops we will practise using the <code>cp</code> command. For now, looking at the examples above to understand its usage. There are also some exercises below to check your understanding.</p> <p>mv, rmdir and mkdir (Moving, removing and making files/directories) </p> <p>The <code>mv</code> command will move files FROM a source TO a destination. It works like copy, except the file is actually moved. If applied to a single file, this effectively changes the name of the file. (Note there is no separate renaming command in Linux). The command also works on directories. </p> <p>Here are some examples (again please do not type these in): </p> Command Function <code>mv myfile yourfile</code> renames file <code>mv ~/data/somefile somefile</code> moves file <code>mv ~/data/somefile yourfile</code> moves and renames <code>mv ~/data/* .</code> moves multiple files <p>There are also the <code>mkdir</code> and <code>rmdir</code> commands:</p> <ul> <li><code>mkdir</code> \u2013 to make a new directory e.g.        <code>mkdir testdir</code> </li> <li><code>rmdir</code> \u2013 to remove an empty directory e.g.   <code>rmdir testdir</code> </li> </ul> <p>You can try these two commands. Open new Terminal and type:</p> <pre><code>mkdir testdir\nls\n</code></pre> <p>In your home directory you will see now a new directory <code>testdir</code>. Now type:</p> <pre><code>rmdir testdir\nls\n</code></pre> <p>You should notice that the <code>testdir</code> has been removed from your home directory.</p> <p>To remove a file you can use <code>rm</code> command. Note that once files are deleted at the command line prompt in a terminal window, unlike in Microsoft Windows, you cannot get files back from the wastebin.</p> <p>e.g.    <code>rm junk.txt</code> (this is an example do not type it in your terminal)</p> <p>Clearing your terminal</p> <p>Often when running many commands, your terminal will be full and difficult to understand. To clear the terminal screen type <code>clear</code>. This is especially helpful command when you have been typing lots of commands and need a clean terminal to help you focus.</p> Linux commands in general  <p>Note that most commands in Linux have a similar syntax:  <code>command name [modifiers/options] input output</code></p> <p>The syntax of the command is very important. There must be spaces in between the different parts of the command. You need to specify input and output. The modifiers (in brackets) are optional and may or may not be needed depending on what you want to achieve. </p> <p>For example, take the following command: </p> <p><code>cp -r /rds/projects/f/fred/data ~/tmp</code>  (This is an example, do not type this) </p> <p>In the above example <code>-r</code> is an option meaning 'recursive' often used with <code>cp</code> and other commands, used in this case to copy a directory including all its content from one directory to another directory.</p>"},{"location":"workshop1/intro-to-linux/#opening-fsl-on-the-bluebear-gui","title":"Opening FSL on the BlueBEAR GUILinux Exercise","text":"<p>FSL (FMRIB Software Library; https://fsl.fmrib.ox.ac.uk/fsl/docs) is a software library containing multiple tools for processing, statistical analyses, and visualisation of magnetic resonance imaging (MRI) data. Subsequent workshops will cover usage of some of the FSL tools for structural, functional and diffusion MRI data. This workshop only covers how to start FSL app on BlueBEAR GUI Linux desktop, and some practical aspects of using FSL, specifically running it in the terminal either in the foreground or in the background. </p> <p>There are several different versions of FSL software available on BlueBEAR. You can search which versions of FSL are available on BlueBEAR as well as all other available software using the following link: https://bear-apps.bham.ac.uk</p> <p>From there you will also find information how to load different software. Below you will find an example of loading one of the available versions of FSL.</p> <p>To open FSL in terminal, you first need to load the FSL app. To load the module for FSL, you need to type in the Terminal a specific command. First, either close the Terminal you have been previously using and open a new one, or simply clean it. Next, type:</p> <p><code>module load FSL/6.0.5.1-foss-2021a</code></p> <p>You will see various processes running the terminal. Once these stopped and you see system prompt in the terminal, type: </p> <p><code>fsl</code></p> <p>This <code>fsl</code> command will initiate the FSL gui as shown below.</p> <p> </p> <p>Now try typing <code>ls</code> in the same terminal window and pressing return. </p> <p>Notice how nothing appears to happen (your keystrokes are shown as being typed in but no actual event seems to be actioned). Indeed, nothing you type is being processed and the commands are being ignored. That is because the <code>fsl</code> command is running in the foreground in the terminal window. Because of that it is blocking other commands from being run in the same terminal.</p> <ul> <li>Now close FSL by clicking on the 'Exit' button in the FSL GUI.  </li> </ul> <p>Notice now that control has been returned to the Terminal and how commands you type are now being acted on. Try typing <code>ls</code> again.</p> <ul> <li> <p>Go back to the terminal window again, but this time type <code>fsl &amp;</code> at the system prompt and press return. Again, you should see the FSL GUI pop up. </p> </li> <li> <p>Now try typing <code>ls</code> in the same Terminal. </p> </li> </ul> <p>Notice that your new commands are now being processed. The <code>fsl</code> command is now running in the background in the Terminal allowing you to run other commands in parallel from the same Terminal. </p> <p>Typing the <code>&amp;</code> after any command makes it run in the background and keeps the Terminal free for you to use. </p> <p>Sometimes you may forget to type <code>&amp;</code> after a command. </p> <ul> <li>Close all open windows, open a new terminal and type <code>fsl</code> (without the &amp;) so that it is running in the foreground. </li> <li>Now hold down the CTRL key and the z key together 'CTRL-z'. </li> </ul> <p>You should get a message like <code>\u201c[1]+ Stopped fsl\u201d</code>. You will notice that the FSL gui is now unresponsive (try clicking on some of the buttons). The <code>fsl</code> process has been suspended. </p> <ul> <li>To make it run again in the background type <code>bg</code> in the terminal window (followed by pressing the return key). </li> </ul> <p>You should find the FSL GUI is now responsive again and input to the terminal now works once more. If you clicked the 'Exit' button when the FSL GUI was unresponsive, FSL might close now.</p> <p>Running and killing commands in the terminal</p> <p>If, for some reason, you want to make the command run in the foreground then rather than typing <code>bg</code> (for background) instead type <code>fg</code> (for foreground).  If you want to kill (rather than suspend) a command that was running in the foreground, press CTRL-c (CTRL key and c key).</p> <p>Linux: some final useful tips</p> <p>TIP 1:</p> <p>When typing a command, or the name of a directory or file you never need to type everything out. The terminal will self-complete the command or file name if you type the TAB key as you go along. Try using TAB key when typing commands or complete path to specific directory.</p> <p>TIP 2:</p> <p>If you need help understanding what the options are, or how to use a command, try adding <code>--help</code> to the end of your command. For example, for better understanding of the <code>du</code> options, type: </p> <p><code>du --help [enter]</code></p> <p>TIP 3:</p> <p>There are many useful online lists of these various commands, for example: www.ss64.com/bash</p> <p>Please complete the following exercises, you should hopefully know which Linux commands to use!</p> <p>(1) clean up your Terminal </p> <p>(2) <code>cd</code> back to your home directory </p> <p>(3) make sure you are in your home directory</p> <p>(4) make new directory called <code>test</code></p> <p>(5) rename this directory to <code>test1</code> and make another directory called <code>test2</code></p> <p>(6) move or copy directory <code>test1</code> to your folder on modules\u2019s RDS project (i.e., <code>rds/projects/c/chechlmy-chbh-mricn/xxx</code>)</p> <p>(7) delete the <code>test1</code> and <code>test2</code> directories and confirm it.</p> <p> The correct commands are provided below. (click to reveal)</p> Linux Commands Exercise (Answers) <ol> <li> <p><code>clear</code></p> </li> <li> <p><code>cd ~</code> or <code>cd /rds/homes/x/xxx</code></p> </li> <li> <p><code>pwd</code></p> </li> <li> <p><code>mkdir test</code></p> </li> <li> <p><code>mv test test1</code> <code>mkdir test2</code></p> </li> <li> <p><code>cp -r test1 /rds/projects/c/chechlmy-chbh-mricn/xxx/</code> or <code>mv test1 /rds/projects/c/chechlmy-chbh-mricn/xxx/</code></p> </li> <li> <p><code>rm -r test1 test2</code> <code>ls</code></p> </li> </ol>"},{"location":"workshop1/workshop1-intro/","title":"Workshop 1 - Introduction to BlueBEAR and Linux","text":"<p>Welcome to the first workshop of the MRICN course!</p> <p>This workshop covers:</p> <ul> <li>Introduction to BlueBEAR portal</li> <li>Using the BlueBEAR Graphical User Interface (GUI) environment</li> <li>Files and Directories in BEAR Portal</li> <li>Introduction to Linux</li> <li>Using the Linux Terminal</li> <li>Basic Linux Commands</li> </ul> <p>Pre-requisites for the workshop</p> <p>Please ensure that you have completed the 'Setting Up' section of this course, as you will require access to the BEAR Portal for this workshop.</p>"},{"location":"workshop1/workshop1-intro/#recommended-reading-and-further-information","title":"Recommended reading and further information","text":"<p>A useful textbook on essential Linux commands:</p> <p> </p> <p>Additional information:</p> <p>There is a detailed guide for accessing BlueBEAR provided by BEAR services:</p> <ul> <li>https://docs.bear.bham.ac.uk/portal/accessing/</li> </ul> <p>There is also CHBH specific BEAR documentation (CHBH-on-BEAR) which extends BEAR technical documentation by providing tutorials and examples for neuroimaging analyses to run on BlueBEAR.</p> <ul> <li>https://chbh-opensource.github.io/chbh-on-bear/</li> </ul> <p>Finally, BEAR services provide Introduction to Linux online resources and in person training:</p> <ul> <li>https://intranet.birmingham.ac.uk/it/teams/infrastructure/research/bear/bear-training/necessities.aspx</li> </ul> <p>The copy of this workshop notes can be found on Canvas 39058 - LM Magnetic Resonance Imaging in Cognitive Neuroscience in Week 01 workshop materials.</p>"},{"location":"workshop8/functional-connectivity/","title":"Functional connectivity analysis of resting-state fMRI data using FSL","text":"<p>This tutorial is based upon the excellent FSL fMRI Resting State Seed-based Connectivity tutorial by Dianne Paterson at the University of Arizona, but which has been adapted to run on the BEAR systems at the University of Birmingham, with some additional material.</p> <p>In this session, we will run a group-level functional connectivity analysis on resting-state fMRI data of three participants. We will specifically look at the functional connectivity of the posterior cingulate cortex (PCC), a region of the default mode network (DMN) that is commonly found to be active in resting-state data. </p> <p>To do this, we will:</p> <ul> <li>extract a mean-timeseries for a PCC seed region for each participant,</li> <li>run single-subject level analyses, one manually and bash scripting the other two, </li> <li>run a group-level analysis using the single-level results </li> <li>Finally, we will figure out which brain regions our active voxels are in, using   atlases in FSL, and Neurosynth.</li> </ul>"},{"location":"workshop8/functional-connectivity/#preparing-the-data","title":"Preparing the data","text":"Setting up <p>Navigate to your shared directory within the MRICN folder and copy the data:</p> <pre><code>cd /rds/projects/c/chechlmy-chbh-mricn/xxx\ncp -r /rds/projects/c/chechlmy-chbh-mricn/aamir_test/SBC .\ncd SBC\nls\n</code></pre> <p>You should see the following:</p> <pre><code>sub1 sub2 sub3\n</code></pre> <p>Each of the folders has a single resting-state scan, called <code>sub1.nii.gz</code>,<code>sub2.nii.gz</code> and <code>sub3.nii.gz</code> respectively. </p> Creating the PCC seed <p>We will now create our seed region for the PCC. To do this, firstly load FSL and <code>fsleyes</code> in the terminal by running: </p> <pre><code>module load FSL/6.0.5.1-foss-2021a\nmodule load FSLeyes/1.3.3-foss-2021a\n</code></pre> <p>Check that we are in the correct directory (blah/your_username/SBC):</p> <pre><code>pwd\n</code></pre> <p>and create a new directory called <code>seed</code>:</p> <pre><code>mkdir seed\n</code></pre> <p>Now when you run <code>ls</code> you should see:</p> <pre><code>seed sub1 sub2 sub3\n</code></pre> <p>Lets open FSLeyes:</p> <pre><code>fsleyes &amp;\n</code></pre> <p>We need to open the standard MNI template brain, select the PCC and make a mask. </p> <p>Here are the following steps: </p> <ol> <li>Navigate to the top menu and click on <code>File \u279c Add standard</code> and select <code>MNI152_T1_2mm_brain.nii.gz</code>.</li> <li>When the image is open, click on <code>Settings \u279c Ortho View 1 \u279c Atlases</code>. An atlas panel then opens on the bottom section.</li> <li>Select <code>Atlas information</code> (if it already hasn't loaded).</li> <li>Ensure Harvard-Oxford Cortical Structural Atlas is selected.</li> <li>Go into 'Atlas search' and type <code>cing</code> in the search box. Check the Cingulate Gyrus, posterior division (lower right) so that it is overlaid on the standard brain. (The full name may be obscured, but you can always check which region you have loaded by looking at the panel on the bottom right).</li> </ol> <p> </p> <p> At this point, your window should look something like this:  </p> <p> </p> <p> To save the seed, click the save symbol which is the first of three icons on the bottom left of the window.  </p> <p> </p> <p>The window that opens up should be your project SBC directory. Open into the <code>seed</code> folder and save your seed as <code>PCC</code>. </p> Extracting the time-series <p>We now need to binarise the seed and to extract the mean timeseries. To do this, leaving FSLeyes open, go into your terminal (you may have to press Enter if some text about dc.DrawText is there) and type:</p> <pre><code>cd seed\nfslmaths PCC -thr 0.1 -bin PCC_bin\n</code></pre> <p>In FSLeyes now click File \u279c Add from file, and select <code>PCC_bin</code> to compare PCC.nii.gz (before binarization) and PCC_bin.nii.gz (after binarization). You should note that the signal values are all 1.0 for the binarized PCC.</p> <p> </p> <p>You can now close FSLeyes.</p> <p>For each subject, you want to extract the average time series from the region defined by the PCC mask. To calculate this value for <code>sub1</code>, do the following: </p> <pre><code>cd ../sub1\nfslmeants -i sub1 -o sub1_PCC.txt -m ../seed/PCC_bin\n</code></pre> <p>This will generate a file within the <code>sub1</code> folder called <code>sub1_PCC.txt</code>. </p> <p>We can have a look at the contents by running <code>cat sub1_PCC.txt</code>. The terminal will print out a list of numbers with the last five being:</p> <pre><code>20014.25528\n20014.919\n20010.17317\n20030.02886\n20066.05141\n</code></pre> <p>This is the mean level of 'activity' for the PCC at each time-point.</p> <p>Now let's repeat this for the other two subjects. </p> <pre><code>cd ../sub2\nfslmeants -i sub2 -o sub2_PCC.txt -m ../seed/PCC_bin\ncd ../sub3\nfslmeants -i sub3 -o sub3_PCC.txt -m ../seed/PCC_bin\n</code></pre> <p>Now if you go back to the SBC directory and list all of the files within the subject folders:</p> <pre><code>cd ..\nls -R\n</code></pre> <p>You should see the following: </p> <p> </p> <p>This is all we need to run the subject and group-level analyses using FEAT.</p>"},{"location":"workshop8/functional-connectivity/#running-the-feat-analyses","title":"Running the FEAT analyses","text":""},{"location":"workshop8/functional-connectivity/#single-subject-analysis","title":"Single-subject analysisExamining the FEAT outputScripting the other two subjects","text":"<p>Close your terminal, open another one, move to your <code>SBC</code> folder, load FSL and open FEAT: </p> <pre><code>cd /rds/projects/c/chechlmy-chbh-mricn/xxx/SBC\nmodule load bear-apps/2022b\nmodule load FSL/6.0.7.6\nsource $FSLDIR/etc/fslconf/fsl.sh\nFeat &amp;\n</code></pre> <p>We will run the first-level analysis for <code>sub1</code>. Set-up the following settings in the respective tabs:</p> <p>Data</p> <p>Number of inputs:</p> <ul> <li>Click 'Select 4D data', then click the folder icon, go into the <code>sub1</code> folder and choose <code>sub1.nii.gz</code>. Click OK. You will see a box saying that the 'Input file has a TR of 1...' this is fine, just click OK again.</li> </ul> <p>Output directory: </p> <ul> <li>Click into the <code>sub1</code> folder and click OK. Nothing will be in the right hand column, but that is because there are no folders within <code>sub1</code>. We will create our <code>.feat</code> folder within <code>sub1</code>. </li> </ul> <p>This is what your data tab should look like (with the input data opened for show).</p> <p> </p> <p>Pre-stats</p> <p>The data has already been pre-processed, so just set Motion correction to 'None' and uncheck BET. Your pre-stats should look like this: </p> <p> </p> <p>Registration</p> <p>Nothing needs to be changed here. </p> <p>Stats</p> <p>Click on 'Full Model Setup' and do the following: </p> <ol> <li>Keep the Number of original EVs as 1.</li> <li>Type PCC for the EV name.</li> <li>Select Custom (1 entry per volume) for the Basic shape. Click into the <code>sub1</code> folder and select <code>sub1_PCC.txt</code>. This is the mean time series of the PCC for sub-001 and is the statistical regressor in our GLM model. This is different from analyses of task-based data which will usually have an <code>events.tsv</code> file with the onset times for each regressor of interest.</li> <li>Select 'None' for Convolution, and uncheck both 'Add temporal derivate' and 'Apply temporal filtering'. </li> </ol> <p>What does this mean?</p> <p>The first-level analysis will subsequently identify brain voxels that show a significant correlation with the seed (PCC) time series data.</p> <p>Your window should look like this: </p> <p> </p> <p>In the same General Linear Model window, click the Contrast &amp; F-tests tab, type PCC in the title, and click Done. </p> <p>A blue and red design matrix will then be displayed. You can close it.</p> <p>Post-stats </p> <p>Nothing needs to be changed here.</p> <p>You are ready to run the first-level analysis. Click Go to run. On BEAR, this should only take a few minutes. </p> <p>To actually examine the output, go to the BEAR Portal and at the menu bar select <code>Files \u279c /rds/projects/c/chechlmy-chbh-mricn/</code> </p> <p> </p> <p>  Then go into <code>SBC/sub1.feat</code>, select <code>report.html</code> and click View (top left of the window). Navigate to the 'Post-stats' tab and examine the outputs. It should look like this:  </p> <p> </p> <p>We can now run the second and third subjects. As we only have three subjects, we could manually run the other two by just changing three things: </p> <ol> <li>The fMRI data path</li> <li>The output directory</li> <li>The <code>sub_PCC.txt</code> path</li> </ol> <p>Whilst it would probably be quicker to do it manually in this case, it is not practical in other instances (e.g., more subjects, subjects with different number of scans etc.). So, instead we will be scripting the first level FEAT analyses for the other two subjects.</p> <p>The importance of scripting</p> <p>Scripting analyses may seem challenging at first, but it is an essential skill of modern neuroimaging research. It enables you to automate repetitive processing steps, dramatically reduces the chance of human error, and ensures your research is reproducible.</p> <p>(Go back into your terminal, you don't need to open a new terminal or close FEAT)</p> <p>The setup for each analysis is saved as a specific file, the <code>design.fsf</code> file within the FEAT output directory. We can see this by opening the <code>design.fsf</code> file for <code>sub1</code>:</p> <pre><code>pwd # make sure you are in your SBC directory e.g., blah/xxx/SBC\ncd sub1.feat\ncat design.fsf\n</code></pre> <p>FEAT acts as a large 'function' with its many variables corresponding to the options that we choose when setting up in the GUI. We just need to change three of these (the three mentioned above) which in the <code>design.fsf</code> file correspond to:</p> <pre><code>set fmri(outputdir) \"/rds/projects/c/chechlmy-chbh-mricn/xxx/SBC/sub1\"\nset feat_files(1) \"/rds/projects/c/chechlmy-chbh-mricn/xxx/SBC/sub1/sub1/\"\nset fmri(custom1) \"/rds/projects/c/chechlmy-chbh-mricn/xxx/SBC/sub1/sub1_PCC.txt\"\n</code></pre> <p>To do this, please copy the <code>run_feat.sh</code> script into your own <code>SBC</code> directory:</p> <pre><code>cd ..\npwd # make sure you are in your SBC directory\ncp /rds/projects/c/chechlmy-chbh-mricn/axs2210/SBC/run_feat.sh .\n</code></pre> <p>This is the script:</p> <pre><code>#!/bin/bash\n\n# Prompt the user for the University account name\nread -p \"Please enter your University account name: \" account_name\n\n# Define the base directory with the user-provided account name\nbase_dir=\"/rds/projects/c/chechlmy-chbh-mricn/${account_name}/SBC\"\n\necho \"Using base directory: $base_dir\"\n\n# Loop over each subject's data\nfor sub in sub2 sub3; do\n    # Define the input .nii.gz file for the subject\n    input_file=\"${base_dir}/${sub}/${sub}.nii.gz\"\n\n    # Define the output FEAT directory\n    output_dir=\"${base_dir}/${sub}.feat\"\n\n    # Define the custom EV file for the subject\n    custom_ev_file=\"${base_dir}/${sub}/${sub}_PCC.txt\"\n\n    # Define the .fsf file for the subject\n    design_file=\"${base_dir}/${sub}.fsf\"\n\n    # Copy the template design file from sub1 and modify it for the current subject\n    cp \"${base_dir}/sub1.feat/design.fsf\" \"$design_file\"\n\n    # Replace the input file path in the design file\n    sed -i \"s|set feat_files(1) \\\".*\\\"|set feat_files(1) \\\"${input_file}\\\"|g\" \"$design_file\"\n\n    # Replace the output FEAT directory in the design file\n    sed -i \"s|set fmri(outputdir) \\\".*\\\"|set fmri(outputdir) \\\"${output_dir}\\\"|g\" \"$design_file\"\n\n    # Replace the custom EV file in the design file\n    sed -i \"s|set fmri(custom1) \\\".*\\\"|set fmri(custom1) \\\"${custom_ev_file}\\\"|g\" \"$design_file\"\n\n    # Run FEAT analysis\n    feat \"$design_file\"\n\n    # Remove the .fsf file from the SBC directory after running FEAT\n    rm -f \"$design_file\"\ndone\n\necho \"FEAT analysis completed for sub2 and sub3.\"\n</code></pre> <p>You can have a look at the script yourself by typing <code>cat run_bash.sh</code>.</p> <p>The first line is always needed to run <code>bash</code> scripts. The rest of the code just replaces the 3 things we wanted to change for the defined subs, sub2 and sub3.</p> <p>Run the code (from your SBC directory) by typing <code>bash run_feat.sh</code>. (It will ask you for your University account name, this is your ADF username (axs2210 for me)).</p> <p>This should take about 5-10 minutes to run on BEAR.</p> <p>After the script has finished running, have a look at the <code>report.html</code> file for both directories, they should look like this:</p> <p>sub2</p> <p> </p> <p> sub3 </p> <p> </p>"},{"location":"workshop8/functional-connectivity/#group-level-analysis","title":"Group-level analysisExamining the output","text":"<p>Ok, so now we have our FEAT directories for all three subjects, we can run the group level analysis. Close FEAT and open a new FEAT by running <code>Feat &amp;</code> in your <code>SBC</code> directory. </p> <p>Here are instructions on how to setup the group-level FEAT:</p> <p>Data </p> <ol> <li>Change 'First-level analysis' to 'Higher-level analysis'</li> <li>Keep the default option, for 'Inputs are lower-level FEAT directories'.</li> <li>Keep the 'Number of inputs' as 3.</li> <li>Click the 'Select FEAT directories'. Click the yellow folder on the right to select the FEAT folder that you had generated from each first-level analysis.</li> </ol> <p>Your window should look like this (before closing the Input window):</p> <p> </p> <p></p> <p>5. Keep 'Use lower-level copes ticked'.</p> <p>6. In 'Output directory' stay in your current directory (it should be SBC), and in the bottom bar, type in <code>PCC_group</code> at the end of the file path. Don't worry about it being empty, FSL will fill out the file path for us. </p> <p>If you click the folder again, it should look similar to this (with your ADF username instead of <code>axs2210</code>: </p> <p> </p> <p> Stats</p> <ol> <li>Leave the 'Mixed effects: FLAME 1' and click Full model setup. </li> <li>In the General Linear Model window, name the model 'PCC' and make sure the EVs are all 1s. </li> </ol> <p>The interface should look like this:</p> <p> </p> <p>After that, click 'Done' and close the GLM design matrix that pops up (you don't need to change anything in the 'Contrasts and F-tests' tab).</p> <p>Post-stats</p> <ol> <li>Change the Z-threshold from 3.1 to 2.3.</li> </ol> <p>Thresholding</p> <p>Why do you think we are lowering this to 2.3 in our analysis instead of keeping it at 3.1?</p> <p>Click 'Go' to run! </p> <p>This should only take about 2-3 minutes. </p> <p>While this is running, you can load the <code>report.html</code> through the file browser as you did for the individual subjects. </p> <p>Click on the 'Results' tab, and then on 'Lower-level contrast 1 (PCC)'. When the analysis has finished, your results should look like this: </p> <p> </p> <p>These are voxels demonstrating significant functional connectivity with the PCC at a group-level (Z &gt; 2.3).</p> <p>So, we have just ran our group-level analysis. Let's have a closer look at the outputted data. </p> <p>Close FEAT and your terminal, open a new terminal, go to your <code>SBC</code> directory and open FSLeyes: </p> <pre><code>cd /rds/projects/c/chechlmy-chbh-mricn/xxx/SBC\nmodule load FSL/6.0.5.1-foss-2021a\nmodule load FSLeyes/1.3.3-foss-2021a\nfsleyes &amp;\n</code></pre> <p>In FSLeyes, open up the standard brain (Navigate to the top menu and click on 'File \u279c Add standard' and select <code>MNI152_T1_2mm_brain.nii.gz</code>). </p> <p>Then add in our contrast image (File  \u279c Add from file, and then go into the <code>PCC_group.gfeat</code> and then into <code>cope1.feat</code> and open the file <code>thresh_zstat1.nii.gz</code>). </p> <p>When opened, change the colour to 'Red-Yellow' and the 'Minimum' up to 2.3 (The max should be around 3.12). If you set the voxel location to (42, 39, 52) your screen should look like this:</p> <p> </p> <p>This is the map that we saw in the <code>report.html</code> file. In fact we can double check this by changing the voxel co-ordinates to (45, 38, 46).</p> <p>Our thresholded image in fsleyes </p> <p> </p> <p> The FEAT output  Our image matches the one on the far right below:  </p> <p> </p>"},{"location":"workshop8/functional-connectivity/#bonus-identifying-regions-of-interest-with-atlases-and-neurosynth","title":"Bonus: Identifying regions of interest with atlases and Neurosynth","text":"<p>So we know which voxels demonstrate significant correlation with the PCC, but what regions of the brain are they in? </p> <p>Let's go through two ways in which we can work this out. </p> <p>Firstly, we can simply just overlap an atlas on the image and see which regions the activated voxels fall under. </p> <p>To do this:</p> <ol> <li>Navigate to the top menu and click on 'Settings \u279c Ortho View 1 \u279c Atlases'. </li> <li>Then at the bottom middle of the window, select the 'Harvard-Oxford Cortical Structural Atlas' and on the window directly next to it on the right, click 'Show/Hide'. </li> <li>The atlas should have loaded up but is blocking the voxels. Change the Opacity to about a quarter. </li> </ol> <p> </p> <p> By having a look at the 'Location' window (bottom left) we can now see that significant voxels of activity are mainly found in the: </p> <p>Right superior lateral occipital cortex</p> <p>Posterior cingulate cortex (PCC) / precuneus</p> <p>Alternatively, we can also use Neurosynth, a website where you can get the resting-state functional connectivity of any voxel location or brain region. It does this by extracting data from studies and performing a meta-analysis on brain imaging studies that have results associated with your voxel/region of interest.</p> <p>About Neurosynth</p> <p>While Neurosynth has been superseded by Neurosynth Compose we will use the original Neurosynth (https://neurosynth.org/) in this tutorial.</p> <p>If you click the following link, you will see regions demonstrating significant connectivity with the posterior cingulate.</p> <p>If you type <code>(46, -70, 32)</code> as co-ordinates in Neurosynth, and then into the MNI co-ordinates section in fsleyes, not into the voxel location, because Neurosynth works with MNI space, you can see that in both cases the right superior lateral occipital cortex is activated. </p> <p>Image orientation</p> <p>Note that the orientations of left and right are different between Neurosynth and FSLsyes!</p> <p>Neurosynth</p> <p>FSLeyes</p> <p> This is a great result given that we only have three subjects!</p> <p>Learning outcomes of this workshop</p> <p>In this workshop, you have:</p> <ul> <li>Created a seed region in the posterior cingulate cortex (PCC) using FSL's standard brain and atlases</li> <li>Extracted mean time-series data from the PCC for three subjects</li> <li>Run a single-subject functional connectivity analysis manually using FEAT</li> <li>Learned to automate analyses by scripting FEAT for multiple subjects using bash</li> <li>Conducted a group-level analysis to identify regions showing functional connectivity with the PCC</li> <li>Used two different methods to identify active brain regions:<ul> <li>FSL's Harvard-Oxford atlas for anatomical localization</li> <li>Neurosynth for validating findings against meta-analytic data</li> </ul> </li> <li>Successfully identified functional connectivity between the PCC and lateral occipital cortex, replicating known patterns of functional connectivity</li> </ul>"}]}